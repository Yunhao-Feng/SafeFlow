import json
import logging
from typing import Any, Dict, List, Optional, Tuple
from openai import OpenAI
from rich.console import Console
from tools.abs_tools import ToolRegistry
from tools.file_system import FileSystemTool
from tools.windowed_editor import WindowedEditorTool
from tools.planning_tool import PlanningTool
from tools.base_tools import BaseTools
from tools.env_management import EnvManagementTool
from traj import TraceTrack
from agent.context_manager import ContextManagerAgent

logger = logging.getLogger(name=__name__)
agent_console = Console()

class DefaultAgent:
    """
    This is the code agent.
    """
    def __init__(self, config, item_id: str, work_root: str = None, agent_name: str = "default") -> None:
        self.config = config
        self.max_turns = self.config.max_turns
        self.api_key = self.config.api_key
        self.api_url = self.config.api_url
        self.agent_name = agent_name
        self.client = OpenAI(api_key=self.api_key, base_url=self.api_url)
        self.model = self.config.model_name
        self.item_id = item_id
        self.work_root = work_root
        self.trace_track = TraceTrack(root_dir=self.config.output_dir, agent_name=agent_name, item_id=item_id)

        # Initialize session state
        self.session_initialized = False
        self.initialization_attempted = False

        # Test retry limitation to prevent infinite loops
        self.test_attempt_count = 0
        self.max_test_attempts = 5  # Maximum number of test retry attempts
        self.consecutive_test_failures = 0
        self.max_consecutive_failures = 3  # Stop if tests fail 3 times in a row

        # Initialize tool registry with all available tools
        self.tool_registry = ToolRegistry()

        # Register all tools with same item_id
        self.tool_registry.register_tool(FileSystemTool(item_id=item_id))
        self.tool_registry.register_tool(WindowedEditorTool(item_id=item_id))

        # Initialize BaseTools with work_root
        self.base_tools = BaseTools(item_id=item_id, work_root=work_root)
        self.tool_registry.register_tool(self.base_tools)

        # Register EnvManagementTool with work_root provider
        self.tool_registry.register_tool(EnvManagementTool(
            item_id=item_id,
            work_root_provider=lambda: self.work_root
        ))

        # Initialize Context Manager Agent for state and memory management
        self.context_manager = ContextManagerAgent(
            config=config,
            item_id=item_id,
            default_agent_name=agent_name
        )

        # Smart initialization state detection - check if we're already in a prepared environment
        self._detect_and_set_initial_state()

        agent_console.print("‚úÖ All Tools registered\n", style="green")
        agent_console.print(self.tool_registry.get_registry_summary())

        # Simplified system message focused on core functionality
        work_root_info = f"Working Directory: {self.work_root or 'Not specified'}"

        self.system_message = f"""You are SafeFlow, an intelligent code analysis and repair agent.

## Current Context
{work_root_info}

## Available Tools
- **file_system**: Find, search, and analyze code files
- **windowed_editor**: Edit files with precise line control
- **env_management**: Run tests, execute commands, check code quality
- **base_tools**: Basic operations (git status, test running, task completion)

## Your Process
1. **Understand**: Read the problem description carefully
2. **Explore**: Use file_system tools to find relevant code
3. **Analyze**: Understand the current behavior and root cause
4. **Fix**: Make targeted changes using windowed_editor
5. **Verify**: Run tests to confirm your fix works
6. **Complete**: Use base_tools__finish_task when done

## Guidelines
- Always use absolute paths: {self.work_root or '/path/to/work'}/filename
- Make minimal, targeted changes
- Test your changes frequently
- Focus on the specific issue described

## Testing Guidelines
- Use env_management__execute_bash to run tests
- Verify both that failing tests now pass AND existing tests still work
- Run `python -m pytest test_path -v` for detailed test output
- **IMPORTANT**: If tests fail repeatedly (3+ times), consider generating a patch instead of retrying
- Focus on creating a working solution rather than achieving 100% test pass rate

## Completion Options
1. **Generate Patch (Recommended for SWE tasks)**: Use `base_tools__generate_patch()` to create a patch file with your changes
2. **Direct Completion**: Use `base_tools__finish_task()` for regular tasks

Start by understanding the problem and exploring the codebase."""

    def _detect_and_set_initial_state(self) -> None:
        """
        Detect if we're already in a prepared environment and set initialization state accordingly.
        This prevents redundant initialization when swe_run.py or other scripts have already prepared the environment.
        """
        try:
            from pathlib import Path

            # Check if work_root is already set and points to a valid directory
            if self.work_root:
                work_path = Path(self.work_root)
                if work_path.exists() and work_path.is_dir():
                    # Check if it's a git repository (strong indicator of prepared environment)
                    git_dir = work_path / ".git"
                    if git_dir.exists():
                        # We're in a prepared repository environment
                        self.session_initialized = True
                        self.initialization_attempted = True  # Prevent initialization prompts

                        # Mark base_tools as initialized too
                        if self.base_tools:
                            self.base_tools._mark_session_initialized(str(work_path))

                        agent_console.print(f"üéØ Detected prepared repository environment at: {work_path}", style="cyan")
                        return

                    # Check if it contains typical project files (another indicator)
                    project_indicators = [".git", "pyproject.toml", "setup.py", "package.json", "Makefile", "README.md"]
                    found_indicators = [f for f in project_indicators if (work_path / f).exists()]

                    if len(found_indicators) >= 2:  # Multiple project files suggest prepared environment
                        self.session_initialized = True
                        self.initialization_attempted = True

                        # Mark base_tools as initialized
                        if self.base_tools:
                            self.base_tools._mark_session_initialized(str(work_path))

                        agent_console.print(f"üéØ Detected prepared project environment at: {work_path} (found: {found_indicators})", style="cyan")
                        return

            # Check base_tools session state as fallback
            if self.base_tools and hasattr(self.base_tools, '_is_session_initialized'):
                if self.base_tools._is_session_initialized():
                    self.session_initialized = True
                    self.initialization_attempted = True
                    agent_console.print("üéØ Detected existing session initialization", style="cyan")
                    return

            agent_console.print("üîß No prepared environment detected, initialization will be required", style="yellow")
        except Exception as e:
            # If detection fails, err on the side of requiring initialization
            agent_console.print(f"‚ö†Ô∏è Environment detection failed: {e}, will require initialization", style="yellow")

    def get_current_work_context(self) -> Dict[str, Any]:
        """Get current work context from context manager."""
        if self.context_manager:
            return self.context_manager.get_current_context()

        # Fallback: try to get from base_tools
        for tool_name, tool in self.tool_registry.tools.items():
            if tool_name == "base_tools" and hasattr(tool, '_get_session_work_root'):
                return {
                    "work_root": tool._get_session_work_root(),
                    "initialized": tool._is_session_initialized() if hasattr(tool, '_is_session_initialized') else False,
                    "message": "Context from base_tools (limited info)"
                }

        return {"work_root": None, "message": "No context available"}

    def before_tool_call(self, tool_name: str, function_name: str) -> str:
        """Get context information before tool calls."""
        context = self.get_current_work_context()
        context_summary = ""

        if self.context_manager:
            context_summary = self.context_manager.get_context_summary_for_agent()
        else:
            context_summary = f"Work Root: {context.get('work_root', 'Not set')}"

        return context_summary

    def update_context_after_tool_call(self, tool_name: str, function_name: str,
                                     tool_result: Dict[str, Any], parameters: Dict[str, Any]) -> None:
        """Update context after tool calls."""
        if not self.context_manager:
            return

        # Update context based on tool usage
        if tool_name == "base_tools":
            if function_name == "base_tools__set_work_root" and tool_result.get("success"):
                work_root = tool_result.get("result", {}).get("work_root")
                if work_root:
                    self.context_manager.update_work_context(work_root=work_root)

            elif function_name == "base_tools__complete_initialization" and tool_result.get("success"):
                result = tool_result.get("result", {})
                work_root = result.get("work_root")
                task_analysis = result.get("task_analysis", {})

                self.context_manager.update_work_context(
                    work_root=work_root,
                    initialization_status="completed"
                )

                # Track completed steps
                for step in result.get("steps_completed", []):
                    self.context_manager.add_completed_step(step)

            # Also handle other initialization functions that complete initialization
            elif "initialization_completed" in tool_result.get("result", {}):
                result = tool_result.get("result", {})
                work_root = result.get("work_root")

                self.context_manager.update_work_context(
                    work_root=work_root,
                    initialization_status="completed"
                )

                # Track completed steps
                for step in result.get("steps_completed", []):
                    self.context_manager.add_completed_step(step)

        elif tool_name == "windowed_editor" or tool_name == "file_system":
            # Track file operations
            if "path" in parameters:
                file_path = parameters["path"]
                operation = function_name.split("__")[-1] if "__" in function_name else function_name
                self.context_manager.track_active_file(file_path, operation)

    def get_enhanced_system_message(self) -> str:
        """Get system message enhanced with current context."""
        base_message = self.system_message

        if self.context_manager:
            context_summary = self.context_manager.get_context_summary_for_agent()

            enhanced_message = f"{base_message}\n\nCURRENT WORK CONTEXT:\n{context_summary}\n\n"

            # Add plan reminder if needed
            if self.context_manager.needs_plan_reminder():
                plans_summary = ", ".join([p.get("type", "unknown") for p in self.context_manager.current_plans[-3:]])
                enhanced_message += f"üìã REMINDER: You have active plans: {plans_summary}\n\n"

            return enhanced_message

        return base_message

    def _route_function(self, openai_function_name: str) -> Tuple[str, str]:
        """
        Map OpenAI tool-call function name -> (tool_name, function_name)

        Your registry is keyed by tool_name then function_name.
        OpenAI tool-call uses only function name in schema; so default to 'file_system'.
        If you later choose to emit names like 'file_system.write_file', this supports it.
        """
        fn = openai_function_name
        for tool_name, tool in self.tool_registry.tools.items():
            # tool.functions keys are callable names on that tool
            if fn in getattr(tool, "functions", {}):
                return tool_name, fn
        raise ValueError(f"No tool found for function {fn}")

    def _enhance_user_prompt_with_initialization(self, user_prompt: str) -> str:
        """
        Enhance user prompt with initialization requirements if needed.
        """
        # Check if user is explicitly asking for reinitialization
        reinit_keywords = ["reinitialize", "reset workspace", "start over", "force_reinit"]
        if any(keyword in user_prompt.lower() for keyword in reinit_keywords):
            self.session_initialized = False  # Reset state for forced reinit
            self.initialization_attempted = False
            return user_prompt  # Let user handle reinitialization themselves

        # If already initialized at agent level, don't require initialization again
        if self.session_initialized:
            return user_prompt

        # Check base_tools state as backup
        base_tools = None
        for tool_name, tool in self.tool_registry.tools.items():
            if tool_name == "base_tools":
                base_tools = tool
                break

        if base_tools and hasattr(base_tools, '_is_session_initialized'):
            if base_tools._is_session_initialized():
                self.session_initialized = True  # Sync agent state
                return user_prompt  # Already initialized

        # Only enhance prompt if initialization hasn't been attempted yet
        if not self.initialization_attempted:
            self.initialization_attempted = True
            return (
                f"USER TASK: {user_prompt}\n\n"
                "INITIALIZATION REQUIREMENT: You must initialize your workspace before proceeding.\n"
                "1. First call: base_tools__check_initialization_status()\n"
                "2. If not initialized, call: base_tools__complete_initialization(task_blob=\"" + user_prompt.replace('"', '\\"') + "\")\n"
                "3. IMMEDIATELY after initialization, create a detailed plan using planning_tool__create_plan() to break down the task into steps\n"
                "4. Then proceed with executing the plan step by step.\n\n"
                "Remember: You MUST create a plan after initialization and before starting work on the task.")
        else:
            # Initialization was attempted but maybe not completed, just return original prompt
            return user_prompt

    def _check_initialization_completion(self, function_name: str, tool_result: Dict[str, Any]) -> None:
        """
        Monitor tool calls to detect initialization completion and plan creation.
        """
        # Check if initialization-related functions completed successfully
        if tool_result.get("success") and function_name in [
            "base_tools__complete_initialization",
            "base_tools__set_work_root"
        ]:
            # Mark as initialized if complete_initialization succeeded
            if function_name == "base_tools__complete_initialization":
                self.session_initialized = True
                if self.context_manager:
                    self.context_manager.record_memory(
                        "milestone",
                        "Workspace initialization completed successfully - plan creation required next"
                    )

            # Also mark as initialized if set_work_root succeeded (backup check)
            elif function_name == "base_tools__set_work_root":
                result_data = tool_result.get("result", {})
                if result_data.get("session_initialized"):
                    self.session_initialized = True


        # Monitor plan creation
        elif function_name == "planning_tool__create_plan" and tool_result.get("success"):
            if self.context_manager:
                # Extract plan content from result
                plan_data = tool_result.get("result", {})
                plan_content = plan_data.get("plan_content", "Plan created successfully")

                # Record the plan in context manager
                self.context_manager.record_plan(
                    plan_content=plan_content,
                    plan_type="initial",
                    metadata={
                        "function_name": function_name,
                        "result": plan_data
                    }
                )
    def run(self, user_prompt: str):
        trace_track = self.trace_track

        # Record task start with context manager if available
        if self.context_manager:
            self.context_manager.record_memory(
                "task_start",
                f"DefaultAgent started task: {user_prompt}"
            )
        tools_schema = [
            {"type": "function", "function": f}
            for f in self.tool_registry.to_openai_functions(enabled_only=True)
        ]

        messages: List[Dict[str, Any]] = []

        def push(msg: Dict[str, Any]):
            """ÂêåÊó∂ÂÜôÂÖ•ÔºöÁªôÊ®°ÂûãÁöÑ messages + ËΩ®Ëøπ trace(json, Â∏¶ time_stamp) + context_manager memory"""
            messages.append(msg)
            trace_track.add_message(msg)

            # Also record in context manager if available
            if self.context_manager:
                self.context_manager.add_default_agent_message(msg)

        # ÂàùÂßãÂåñÊ∂àÊÅØ - ‰ΩøÁî®Â¢ûÂº∫ÁöÑÁ≥ªÁªüÊ∂àÊÅØ
        enhanced_system_message = self.get_enhanced_system_message()
        push({"role": "system", "content": enhanced_system_message})

        # Ê£ÄÊü•Âπ∂ÂºïÂØºÂàùÂßãÂåñ
        enhanced_prompt = self._enhance_user_prompt_with_initialization(user_prompt)
        push({"role": "user", "content": enhanced_prompt})

        # ‰øùÂ≠òÂ∑•ÂÖ∑schemaÂà∞outputsÁõÆÂΩï‰æø‰∫éË∞ÉËØïÂíåÂàÜÊûê
        trace_track.save_json(f"{self.agent_name}_tools_schema.json", tools_schema)

        for turn in range(1, self.max_turns + 1):

            # Check if plan reminder is needed (context manager)
            if self.context_manager:
                reminder_data = self.context_manager.check_plan_reminder_needed()
                if reminder_data:
                    # Add reminder message to conversation
                    reminder_msg = {"role": "system", "content": reminder_data["message"]}
                    push(reminder_msg)

                # Add working directory reminder each turn (only after initialization)
                if self.context_manager and self.context_manager.should_remind_work_dir():
                    work_dir_reminder = self.context_manager.get_working_directory_reminder()
                    work_dir_msg = {"role": "system", "content": work_dir_reminder}
                    push(work_dir_msg)

            # Use context_manager's memory management to get appropriately sized messages
            # This ensures we don't exceed token limits while preserving important context
            actual_messages_for_llm = messages
            if self.context_manager:
                try:
                    # Get summarized messages if needed, otherwise original messages
                    summarized_messages = self.context_manager.get_summarized_messages()
                    if summarized_messages != self.context_manager.default_agent_messages:
                        # Context manager applied summarization, use the summarized version
                        actual_messages_for_llm = summarized_messages
                        agent_console.print(f"üß† Using summarized messages: {len(summarized_messages)} vs {len(messages)}", style="blue")
                except Exception as e:
                    logger.warning(f"Failed to get summarized messages, using original: {e}")
                    actual_messages_for_llm = messages

            resp = self.client.chat.completions.create(
                model=self.model,
                messages=actual_messages_for_llm,
                tools=tools_schema,
                tool_choice="auto",
            )
            messages = actual_messages_for_llm

            choice = resp.choices[0]
            msg = choice.message
            content = getattr(msg, "content", None)
            tool_calls = getattr(msg, "tool_calls", None) or []
            # assistant messageÔºàÂ∏¶ tool_calls Êó∂ content ÂèØËÉΩ‰∏∫ NoneÔºåËøôÊ≤°ÈóÆÈ¢òÔºâ
            assistant_entry: Dict[str, Any] = {"role": "assistant", "content": content}

            # ÁæéÂåñËæìÂá∫ÊòæÁ§∫
            if content:
                agent_console.print(f"[bold green]Agent Turn {turn}[/bold green]: {content}")
            elif tool_calls:
                tool_names = [tc.function.name for tc in tool_calls]
                agent_console.print(f"[bold green]Agent Turn {turn}[/bold green]: [cyan]Using tools[/cyan]: {', '.join(tool_names)}")
            else:
                agent_console.print(f"[bold green]Agent Turn {turn}[/bold green]: [yellow]No response content[/yellow]")

            if tool_calls:
                assistant_entry["tool_calls"] = [
                    {
                        "id": tc.id,
                        "type": tc.type,
                        "function": {
                            "name": tc.function.name,
                            "arguments": tc.function.arguments,
                        },
                    }
                    for tc in tool_calls
                ]

            push(assistant_entry)

            # 1) Ê≤°Êúâ tool_callsÔºåËøõÂÖ•‰∏ã‰∏ÄËΩÆÔºåÂõ†‰∏∫ÁªìÊùü‰πüÂæótool_calss
            if not tool_calls:
                continue

            # 2) Êúâ tool_callsÔºöÈÄê‰∏™ÊâßË°åÂ∑•ÂÖ∑
            for tc in tool_calls:
                fn_name = tc.function.name
                args_raw = tc.function.arguments or "{}"
                try:
                    tool_name, function_name = self._route_function(fn_name)
                except Exception as e:
                    tool_result = {"success": False, "error": f"Bad tool names: {e}", "raw": fn_name}

                # Ëß£ÊûêÂèÇÊï∞ÔºàÂ§±Ë¥•‰πüË¶ÅÂõûÂ°´ tool Ê∂àÊÅØÔºâ
                try:
                    args = json.loads(args_raw) if isinstance(args_raw, str) else (args_raw or {})
                    if not isinstance(args, dict):
                        raise ValueError("Tool arguments must be a JSON object/dict")
                except Exception as e:
                    tool_result = {"success": False, "error": f"Bad tool arguments: {e}", "raw": args_raw}
                else:
                    tool_result = self.tool_registry.call_function(
                        tool_name=tool_name,
                        function_name=function_name,
                        parameters=args,
                    )

                # tool messageÔºö‰∏∫‰∫ÜË¥¥Âêà‰Ω†ÁªôÁöÑÁ§∫‰æãÔºåÂä†‰∏ä name Â≠óÊÆµÔºàÂèØÈÄâ‰ΩÜÊé®ËçêÔºâ
                tool_msg = {
                    "role": "tool",
                    "tool_call_id": tc.id,
                    "name": fn_name,  # ‰æãÂ¶Ç "write_file" / "finish_task"
                    "content": json.dumps(tool_result, ensure_ascii=False),
                }
                push(tool_msg)

                # Monitor initialization completion
                self._check_initialization_completion(function_name, tool_result)

                # Monitor test attempts to prevent infinite loops
                self._monitor_test_attempts(function_name, tool_result)

                # Update context after tool call
                self.update_context_after_tool_call(tool_name, function_name, tool_result, args)

                # 3) Â¶ÇÊûúË∞ÉÁî® finish_taskÔºöÊèêÂâçÈÄÄÂá∫ÔºàÊé®ËçêÂè™Áî®ÂÆÉ‰Ωú‰∏∫"ÂÆåÊàê‰ø°Âè∑"Ôºâ
                if function_name == "base_tools__finish_task":
                    # Record task completion with context manager if available
                    if self.context_manager:
                        self.context_manager.record_memory(
                            "task_completed",
                            content or "Task finished by DefaultAgent"
                        )
                    return {"success": True, "final": content, "messages": messages}

        return {
            "success": False,
            "error": f"Reached max_turns={self.max_turns} without finish_task or final response.",
            "messages": messages,
        }

    def _monitor_test_attempts(self, function_name: str, tool_result: Dict[str, Any]) -> None:
        """
        Monitor test attempts to prevent infinite testing loops.
        """
        # Check if this is a test-related function
        test_functions = [
            "env_management__execute_bash",  # Running pytest directly
            "env_management__run_pytest_smart",  # Smart pytest runner
        ]

        # Check if the bash command looks like a test command
        is_test_command = False
        if function_name == "env_management__execute_bash":
            # Check if result contains test-related keywords
            result_str = str(tool_result).lower()
            if any(keyword in result_str for keyword in ["pytest", "test_", "test/", "tests/"]):
                is_test_command = True
        elif function_name in test_functions:
            is_test_command = True

        if is_test_command:
            self.test_attempt_count += 1

            # Check if test failed
            test_success = tool_result.get("success", False)
            if not test_success:
                self.consecutive_test_failures += 1
            else:
                self.consecutive_test_failures = 0  # Reset on success

            # Log warning if approaching limits
            if self.test_attempt_count >= self.max_test_attempts - 1:
                agent_console.print(
                    f"‚ö†Ô∏è [yellow]Warning[/yellow]: Test attempt {self.test_attempt_count}/{self.max_test_attempts}. "
                    "Consider generating a patch if tests keep failing.",
                    style="yellow"
                )
            elif self.consecutive_test_failures >= self.max_consecutive_failures - 1:
                agent_console.print(
                    f"‚ö†Ô∏è [yellow]Warning[/yellow]: {self.consecutive_test_failures} consecutive test failures. "
                    "Consider alternative approach or generate patch.",
                    style="yellow"
                )

            # Record in context manager if available
            if self.context_manager:
                self.context_manager.record_memory(
                    "test_attempt",
                    f"Test attempt {self.test_attempt_count}: {function_name} - {'Success' if test_success else 'Failed'}"
                )