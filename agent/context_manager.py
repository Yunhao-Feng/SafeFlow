"""
Context Manager Agent for SafeFlow - Memory and State Management

This agent is responsible for:
- Maintaining complete conversation memory from DefaultAgent (no truncation)
- Managing plans generated by DefaultAgent
    - Summarizing memory when token count exceeds threshold (500K tokens)
- Reminding DefaultAgent of initial plans after 30+ turns
- Outputting trace.json files like DefaultAgent

Has same item_id as DefaultAgent but different agent_name for clear separation.
"""

import json
import logging
import tiktoken
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple
from openai import OpenAI
from rich.console import Console
from tools.abs_tools import ToolRegistry
from tools.context_tools import ContextTools
from traj import TraceTrack
from pathlib import Path

logger = logging.getLogger(name=__name__)
context_console = Console()


class ContextManagerAgent:
    """
    Context Manager Agent for SafeFlow.

    Manages complete memory, state, and coordination with DefaultAgent.
    Uses same item_id as DefaultAgent but different agent_name.
    """

    def __init__(self, config, item_id: str, default_agent_name: str = "default") -> None:
        self.config = config
        self.api_key = self.config.api_key
        self.api_url = self.config.api_url
        self.item_id = item_id

        # Context manager has different agent_name but same item_id
        self.agent_name = f"{default_agent_name}_context"

        self.client = OpenAI(api_key=self.api_key, base_url=self.api_url)
        self.model = self.config.model_name

        # Initialize trace tracking for context agent (outputs trace.json like DefaultAgent)
        self.trace_track = TraceTrack(
            root_dir=self.config.output_dir,
            agent_name=self.agent_name,
            item_id=item_id
        )

        # Context agent uses specialized tools for plan recording
        self.tool_registry = ToolRegistry()

        # Register context-specific tools
        context_tools = ContextTools(item_id=item_id)
        self.tool_registry.register_tool(context_tools)

        context_console.print(f"âœ… Context Manager Agent '{self.agent_name}' initialized", style="blue")
        context_console.print(f"ðŸ“‹ Item ID: {item_id}")
        context_console.print(f"ðŸ”§ Tools: {len(self.tool_registry.get_all_tools())}")

        # Memory management (maintain DefaultAgent's complete trace format)
        self.default_agent_messages: List[Dict[str, Any]] = []  # Complete conversation history
        self.current_plans: List[Dict[str, Any]] = []  # Plans generated by DefaultAgent
        self.turn_count = 0  # Track DefaultAgent turns
        self.token_threshold = 500_000 # 500K tokens threshold for summarization (about 1,000 pages of text)
        self.current_turn_tokens = 0  # Track current turn tokens from DefaultAgent
        self.plan_reminder_threshold = 30  # Remind after 30 turns

        # Initialize tokenizer for token counting
        try:
            self.tokenizer = tiktoken.encoding_for_model("gpt-4")
        except Exception:
            self.tokenizer = tiktoken.get_encoding("cl100k_base")  # fallback

        # ContextManager is now a pure state management utility
        # No LLM calls needed - just state tracking and coordination

        # Session state
        self.session_active = True
        self.last_plan_reminder_turn = 0

        # Enhanced state management
        self.current_state = {
            "work_root": None,
            "current_task": None,
            "completed_steps": [],
            "active_files": [],
            "environment_setup": {},
            "last_activity": None
        }

    def _count_tokens(self, text: str) -> int:
        """Count tokens in text using tiktoken."""
        try:
            return len(self.tokenizer.encode(text))
        except Exception:
            # Fallback to rough estimation
            return len(text.split()) * 1.3

    def _calculate_total_tokens(self) -> int:
        """Calculate total tokens in current conversation memory."""
        total_tokens = 0
        for message in self.default_agent_messages:
            content = message.get("content", "")
            if content:
                total_tokens += self._count_tokens(str(content))

            # Count tokens in tool calls if present
            if "tool_calls" in message:
                tool_calls_str = json.dumps(message["tool_calls"], ensure_ascii=False)
                total_tokens += self._count_tokens(tool_calls_str)

        return total_tokens

    def _route_function(self, openai_function_name: str) -> Tuple[str, str]:
        """Route function calls to context_tools."""
        # Check for tool-prefixed function names
        if "__" in openai_function_name:
            parts = openai_function_name.split("__", 1)
            if len(parts) == 2:
                tool_name, func_name = parts
                return tool_name, openai_function_name

        # Default to context_tools for all functions
        return "context_tools", openai_function_name

    def add_default_agent_message(self, message: Dict[str, Any]) -> None:
        """
        Add a message from DefaultAgent to memory (complete, no truncation).
        """
        # Add complete message to memory
        self.default_agent_messages.append(message.copy())

        # Increment turn count if it's an assistant message
        if message.get("role") == "assistant":
            self.turn_count += 1

        # Log memory addition if trace is active
        total_tokens = self._calculate_total_tokens()
        if hasattr(self, 'trace_track'):
            try:
                self.trace_track.add_message({
                    "role": "system",
                    "content": f"Added DefaultAgent message to memory. Total messages: {len(self.default_agent_messages)}, Total tokens: ~{total_tokens}"
                })
            except Exception:
                pass  # Don't fail if trace logging fails

    def notify_turn_tokens(self, prompt_tokens: int) -> None:
        """
        Receive token count notification from DefaultAgent.
        Used to track current turn token usage for summarization decisions.
        """
        self.current_turn_tokens = prompt_tokens
        self.turn_count += 1

        # Log token notification
        if hasattr(self, 'trace_track'):
            try:
                self.trace_track.add_message({
                    "role": "system",
                    "content": f"Turn {self.turn_count}: Received token notification - {prompt_tokens} prompt tokens"
                })
            except Exception:
                pass

        # Check if summarization is needed based on current turn tokens
        if prompt_tokens > self.token_threshold:
            context_console.print(f"ðŸ”¥ High token usage detected: {prompt_tokens} tokens (threshold: {self.token_threshold})", style="yellow")

    def should_summarize_context(self) -> bool:
        """
        Check if context should be summarized based on total token usage.
        Returns True if total conversation tokens exceed threshold.
        """
        total_tokens = self._calculate_total_tokens()
        return total_tokens > self.token_threshold

    def get_summarized_messages(self) -> List[Dict[str, Any]]:
        """
        Get messages for DefaultAgent with summarization applied when needed.

        Strategy:
        - Keep recent turns (last 5 turns)
        - Keep initial turns (first 5 turns)
        - Summarize middle turns using context agent
        - Combine with current plans and state
        """
        if not self.should_summarize_context() or len(self.default_agent_messages) <= 10:
            # No summarization needed - return original messages
            return self.default_agent_messages.copy()

        # Apply summarization strategy
        try:
            return self._apply_smart_summarization()
        except Exception as e:
            logger.warning(f"Summarization failed: {e}, returning original messages")
            return self.default_agent_messages.copy()

    def _apply_smart_summarization(self) -> List[Dict[str, Any]]:
        """
        Apply intelligent summarization keeping important parts of conversation.
        """
        messages = self.default_agent_messages.copy()

        if len(messages) <= 10:
            return messages

        # Strategy: Keep first 3, last 7, summarize middle
        keep_first = 5
        keep_last = 5

        if len(messages) <= keep_first + keep_last:
            return messages

        # Extract parts to keep
        initial_messages = messages[:keep_first]
        recent_messages = messages[-keep_last:]
        middle_messages = messages[keep_first:-keep_last]

        # Create summary of middle messages
        summary_content = self._create_middle_summary(middle_messages)

        # Construct summarized messages
        summarized_messages = initial_messages.copy()

        # Add summary message using assistant role to maintain conversation flow
        summarized_messages.append({
            "role": "assistant",
            "content": f"ðŸ“ **CONTEXT SUMMARY** ({len(middle_messages)} messages summarized):\n\n{summary_content}\n\n*[This summary was generated by the context manager to maintain conversation flow while staying within token limits]*"
        })

        # Add recent messages
        summarized_messages.extend(recent_messages)

        context_console.print(f"ðŸ“ Applied summarization: {len(messages)} â†’ {len(summarized_messages)} messages", style="blue")

        return summarized_messages

    def _create_middle_summary(self, middle_messages: List[Dict[str, Any]]) -> str:
        """
        Create a comprehensive summary of middle conversation messages using LLM.
        """
        try:
            if not middle_messages:
                return "No middle messages to summarize."

            # Prepare messages for LLM summarization
            messages_to_summarize = json.dumps(middle_messages, ensure_ascii=False, indent=1)

            # Add context about current state
            context_info = []
            if self.current_plans:
                plan_types = [p.get("type", "unknown") for p in self.current_plans[-3:]]
                context_info.append(f"Active plans: {', '.join(plan_types)}")
            if self.current_state.get("work_root"):
                context_info.append(f"Working directory: {self.current_state['work_root']}")

            context_str = " | ".join(context_info) if context_info else "No additional context"

            summary_prompt = (
                "You are a conversation summarizer for a coding agent. Please create a concise but comprehensive summary "
                "of the following conversation segment between a coding agent and its tools. Focus on:\n\n"
                "1. Key actions taken and tools used\n"
                "2. Important decisions or milestones reached\n"
                "3. Files created, modified, or analyzed\n"
                "4. Any errors encountered and how they were resolved\n"
                "5. Overall progress toward the task goals\n\n"
                "Keep the summary informative but concise (2-4 sentences). "
                "This summary will be inserted into the ongoing conversation to maintain context.\n\n"
                f"Current context: {context_str}\n\n"
                f"Conversation segment to summarize ({len(middle_messages)} messages):\n{messages_to_summarize}"
            )

            summarization_messages = [
                {"role": "system", "content": "You are an expert at summarizing technical conversations between AI agents and tools. Create clear, actionable summaries."},
                {"role": "user", "content": summary_prompt}
            ]

            # Call LLM for summarization
            resp = self.client.chat.completions.create(
                model=self.model,
                messages=summarization_messages,
                temperature=0.1,  # Low temperature for consistent, factual summaries
                max_tokens=500    # Limit summary length
            )

            summary_content = resp.choices[0].message.content.strip()

            # Log the summarization in trace if available
            if hasattr(self, 'trace_track'):
                try:
                    self.trace_track.add_message({
                        "role": "system",
                        "content": f"Context agent created LLM summary for {len(middle_messages)} middle messages"
                    })
                except:
                    pass

            return summary_content

        except Exception as e:
            logger.warning(f"LLM summarization failed: {e}, falling back to simple summary")
            # Fallback to simple summary if LLM call fails
            return self._create_simple_middle_summary(middle_messages)

    def _create_simple_middle_summary(self, middle_messages: List[Dict[str, Any]]) -> str:
        """
        Fallback: Create a simple summary without LLM when LLM summarization fails.
        """
        # Extract key information from middle messages (original logic)
        summary_parts = []
        tool_calls = []
        key_events = []

        for msg in middle_messages:
            if msg.get("role") == "assistant" and msg.get("tool_calls"):
                for tool_call in msg.get("tool_calls", []):
                    func_info = tool_call.get("function", {})
                    tool_calls.append(func_info.get("name", "unknown_function"))

            elif msg.get("role") == "tool":
                tool_name = msg.get("name", "unknown_tool")
                try:
                    content = json.loads(msg.get("content", "{}"))
                    success = content.get("success", False)
                    key_events.append(f"{tool_name}: {'âœ“' if success else 'âœ—'}")
                except:
                    key_events.append(f"{tool_name}: executed")

        # Build summary
        if tool_calls:
            summary_parts.append(f"Tool calls executed: {', '.join(set(tool_calls))}")
        if key_events:
            summary_parts.append(f"Key results: {'; '.join(key_events[:10])}")
        if self.current_plans:
            plan_types = [p.get("type", "unknown") for p in self.current_plans[-3:]]
            summary_parts.append(f"Active plans: {', '.join(plan_types)}")
        if self.current_state.get("work_root"):
            summary_parts.append(f"Working in: {self.current_state['work_root']}")

        return "\\n".join(summary_parts) if summary_parts else "Conversation continued with various tool interactions."

    def _summarize_memory(self) -> Dict[str, Any]:
        """
        Summarize conversation memory using LLM when token threshold is exceeded.
        """
        try:
            # Prepare messages for summarization
            messages_text = json.dumps(self.default_agent_messages, ensure_ascii=False, indent=2)

            summary_prompt = (
                "Please provide a comprehensive summary of this conversation history. "
                "Include key decisions, important milestones, task progress, and any critical context "
                "that should be preserved for ongoing work. Focus on maintaining continuity."
            )

            messages = [
                {"role": "system", "content": "You are a conversation summarizer. Create detailed, comprehensive summaries."},
                {"role": "user", "content": f"{summary_prompt}\\n\\nConversation to summarize:\\n{messages_text}"}
            ]

            # Call LLM for summarization and log the interaction
            if hasattr(self, 'trace_track'):
                # Log the request
                for msg in messages:
                    self.trace_track.add_message(msg)

            resp = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.1
            )

            summary = resp.choices[0].message.content

            # Log the response
            if hasattr(self, 'trace_track'):
                self.trace_track.add_message({
                    "role": "assistant",
                    "content": summary
                })

            # Replace old messages with summary
            summary_message = {
                "role": "system",
                "content": f"[MEMORY SUMMARY - {datetime.now().isoformat()}]\\n{summary}",
                "metadata": {
                    "summarized_at": datetime.now().isoformat(),
                    "original_message_count": len(self.default_agent_messages),
                    "original_token_count": self._calculate_total_tokens()
                }
            }

            # Keep only recent messages + summary
            recent_messages = self.default_agent_messages[-20:]  # Keep last 20 messages
            self.default_agent_messages = [summary_message] + recent_messages

            context_console.print(f"ðŸ“ Memory summarized: {len(recent_messages)} recent messages kept", style="yellow")

            return {"success": True, "summary": summary, "messages_kept": len(recent_messages)}

        except Exception as e:
            logger.error(f"Failed to summarize memory: {e}")
            return {"success": False, "error": str(e)}

    def record_plan(self, plan_content: str, plan_type: str = "initial", metadata: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        Record a plan created by DefaultAgent.
        """
        try:
            plan_record = {
                "plan_content": plan_content,
                "plan_type": plan_type,
                "metadata": metadata or {},
                "created_at": datetime.now().isoformat(),
                "turn_number": self.turn_count,
                "created_by": "default_agent"
            }

            # Add to current plans
            self.current_plans.append(plan_record)

            # Log plan recording if trace is active
            if hasattr(self, 'trace_track'):
                self.trace_track.add_message({
                    "role": "system",
                    "content": f"Plan recorded: {plan_type} - {plan_content[:100]}..."
                })

            context_console.print(f"ðŸ“‹ Plan recorded: {plan_type}", style="green")

            return {"success": True, "plan_count": len(self.current_plans)}

        except Exception as e:
            return {"success": False, "error": f"Failed to record plan: {e}"}

    def record_memory(self, memory_type: str, content: str) -> Dict[str, Any]:
        """
        Record important conversation memory or decisions.
        """
        try:
            memory_record = {
                "role": "system",
                "content": f"[{memory_type.upper()}] {content}",
                "metadata": {
                    "memory_type": memory_type,
                    "recorded_at": datetime.now().isoformat(),
                    "turn_number": self.turn_count
                }
            }

            # Add to conversation memory
            self.default_agent_messages.append(memory_record)

            # Log memory recording if trace is active
            if hasattr(self, 'trace_track'):
                self.trace_track.add_message(memory_record)

            return {"success": True, "message": "Memory recorded"}

        except Exception as e:
            return {"success": False, "error": f"Failed to record memory: {e}"}

    def check_plan_reminder_needed(self) -> Optional[Dict[str, Any]]:
        """
        Check if DefaultAgent needs to be reminded of initial plans.
        Returns reminder data if needed, None otherwise.
        """
        if (self.turn_count >= self.plan_reminder_threshold and
            self.turn_count - self.last_plan_reminder_turn >= self.plan_reminder_threshold and
            len(self.current_plans) > 0):

            # Find initial plan
            initial_plans = [p for p in self.current_plans if p["plan_type"] == "initial"]

            if initial_plans:
                self.last_plan_reminder_turn = self.turn_count

                reminder_data = {
                    "reminder_needed": True,
                    "turn_count": self.turn_count,
                    "initial_plan": initial_plans[0],
                    "total_plans": len(self.current_plans),
                    "message": (
                        f"PLAN REMINDER: You started with the following plan at turn {initial_plans[0]['turn_number']}. "
                        f"Consider reviewing your progress and approach:\\n\\n"
                        f"{initial_plans[0]['plan_content']}"
                    )
                }

                # Log reminder if trace is active
                if hasattr(self, 'trace_track'):
                    self.trace_track.add_message({
                        "role": "system",
                        "content": reminder_data["message"]
                    })

                context_console.print(f"â° Plan reminder triggered at turn {self.turn_count}", style="cyan")

                return reminder_data

        return None

    def get_current_memory_summary(self) -> Dict[str, Any]:
        """Get current memory and plan summary."""
        try:
            return {
                "success": True,
                "result": {
                    "item_id": self.item_id,
                    "agent_name": self.agent_name,
                    "memory_stats": {
                        "total_messages": len(self.default_agent_messages),
                        "total_tokens": self._calculate_total_tokens(),
                        "turn_count": self.turn_count
                    },
                    "plan_stats": {
                        "total_plans": len(self.current_plans),
                        "plan_types": [p["plan_type"] for p in self.current_plans]
                    },
                    "recent_messages": self.default_agent_messages[-5:],  # Last 5 messages
                    "current_plans": self.current_plans
                }
            }
        except Exception as e:
            return {"success": False, "error": f"Failed to get memory summary: {e}"}

    def save_context_state(self, filepath: str = None) -> Dict[str, Any]:
        """Save complete context state including memory and plans."""
        try:
            if not filepath:
                filepath = f".safeflow_context_{self.item_id}.json"

            context_data = {
                "item_id": self.item_id,
                "agent_name": self.agent_name,
                "session_active": self.session_active,
                "turn_count": self.turn_count,
                "memory_stats": {
                    "total_messages": len(self.default_agent_messages),
                    "total_tokens": self._calculate_total_tokens()
                },
                "current_plans": self.current_plans,
                "saved_at": datetime.now().isoformat()
            }

            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(context_data, f, ensure_ascii=False, indent=2)

            return {"success": True, "filepath": filepath}

        except Exception as e:
            logger.error(f"Failed to save context state: {e}")
            return {"success": False, "error": str(e)}

    def get_tool_info(self) -> Dict[str, Any]:
        """Get information about available tools for this context agent."""
        return {
            "agent_name": self.agent_name,
            "item_id": self.item_id,
            "tool_registry_summary": self.tool_registry.get_registry_summary(),
            "available_functions": self.tool_registry.to_openai_functions()
        }

    def update_work_context(self, work_root: str = None, task_description: str = None) -> None:
        """Update work context with new information."""
        old_work_root = self.current_state.get("work_root")

        if work_root:
            self.current_state["work_root"] = work_root
            # Log work directory change
            if old_work_root != work_root:
                context_console.print(f"ðŸ“ Work directory changed: {old_work_root} â†’ {work_root}", style="cyan")

        if task_description:
            self.current_state["current_task"] = task_description

        self.current_state["last_activity"] = datetime.now().isoformat()

        # Log context update for tracing
        self.trace_track.add_message({
            "role": "system",
            "content": f"Context updated: work_root={work_root}, task={task_description}"
        })

    def get_current_context(self) -> Dict[str, Any]:
        """Get current work state for agent awareness."""
        return {
            **self.current_state,
            "turn_count": self.turn_count,
            "total_messages": len(self.default_agent_messages),
            "active_plans": len(self.current_plans),
            "session_active": self.session_active
        }

    def add_completed_step(self, step_description: str) -> None:
        """Add a completed step to the context."""
        if step_description not in self.current_state["completed_steps"]:
            self.current_state["completed_steps"].append(step_description)
            self.current_state["last_activity"] = datetime.now().isoformat()

    def track_active_file(self, file_path: str, operation: str = "accessed") -> None:
        """Track files being actively worked on."""
        file_entry = {
            "path": file_path,
            "operation": operation,
            "timestamp": datetime.now().isoformat()
        }

        # Keep only recent file activities (last 10)
        self.current_state["active_files"] = (
            [file_entry] +
            [f for f in self.current_state["active_files"] if f["path"] != file_path]
        )[:10]

    def update_environment_setup(self, key: str, value: Any) -> None:
        """Update environment setup information."""
        self.current_state["environment_setup"][key] = value
        self.current_state["last_activity"] = datetime.now().isoformat()

    def get_context_summary_for_agent(self) -> str:
        """Get a formatted context summary for inclusion in agent prompts."""
        context = self.get_current_context()

        summary_parts = [
            f"ðŸŽ¯ Current Task: {context.get('current_task', 'None specified')}",
            f"ðŸ“ Work Root: {context.get('work_root', 'Not set')}",
        ]

        if context.get('completed_steps'):
            summary_parts.append(f"âœ… Completed: {len(context['completed_steps'])} steps")

        if context.get('active_files'):
            recent_files = [f["path"] for f in context['active_files'][:3]]
            summary_parts.append(f"ðŸ“ Recent Files: {', '.join(recent_files)}")

        return " | ".join(summary_parts)

    def needs_plan_reminder(self) -> bool:
        """Check if DefaultAgent needs a plan reminder."""
        return (
            self.turn_count - self.last_plan_reminder_turn > self.plan_reminder_threshold
            and len(self.current_plans) > 0
        )

    def needs_context_reminder(self) -> bool:
        """Check if DefaultAgent needs a work context reminder."""
        return self.turn_count > 0 and self.turn_count % 10 == 0

    def get_context_reminder_data(self) -> Optional[Dict[str, Any]]:
        """Get work context reminder data for DefaultAgent."""
        if not self.needs_context_reminder():
            return None

        context_summary = self.get_context_summary_for_agent()

        return {
            "reminder_needed": True,
            "turn_count": self.turn_count,
            "message": f"CURRENT WORK CONTEXT: {context_summary}"
        }

    def get_working_directory_reminder(self) -> str:
        """Get current working directory reminder for each turn."""
        work_root = self.current_state.get('work_root')
        if work_root:
            return f"Now, we are working in directory: {work_root}"
        return "Working directory not yet set."

    def should_remind_work_dir(self) -> bool:
        """Check if we should remind about working directory each turn."""
        return self.current_state.get('work_root') is not None
